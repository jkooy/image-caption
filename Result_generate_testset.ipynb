{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle \n",
    "import os\n",
    "from torchvision import transforms \n",
    "from build_vocab import Vocabulary\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import nltk\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = 'resnet152+lstm+hidden_size512+lr_1e-3/models/encoder-5-3000.pkl'\n",
    "decoder_path = 'resnet152+lstm+hidden_size512+lr_1e-3/models/decoder-5-3000.pkl'\n",
    "#image_dir = '/datasets/COCO-2015/val2014'\n",
    "image_dir = '/datasets/COCO-2015/test2015'\n",
    "#caption_path = '/datasets/ee285f-public/COCO-Annotations/annotations_trainval2014/captions_val2014.json'\n",
    "caption_path = '/datasets/ee285f-public/COCO-Annotations/image_info_test2015/image_info_test2015.json'\n",
    "vocab_path = './vocab.pkl'\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "batch_size = 1\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ \n",
    "        transforms.Resize((240, 240)), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                             (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(data.Dataset):\n",
    "    def __init__(self, root, json, vocab, transform=None):\n",
    "        \n",
    "        self.root = root\n",
    "        self.coco = COCO(json)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        #self.ids = list(self.coco.anns.keys())\n",
    "        self.vocab = vocab\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        coco = self.coco\n",
    "        vocab = self.vocab\n",
    "        ann_id = self.ids[index]\n",
    "        #img_id = coco.anns[ann_id]['image_id']\n",
    "        img_id = self.ids[index]\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "\n",
    "        image = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            image = image.unsqueeze(0)\n",
    "        return image, img_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(root, json, vocab, transform, batch_size, shuffle, num_workers):\n",
    "    coco = CocoDataset(root=root,\n",
    "                       json=json,\n",
    "                       vocab=vocab,\n",
    "                       transform=transform)\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset=coco, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=shuffle,\n",
    "                                              num_workers=num_workers)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(image_dir,caption_path,\n",
    "                         vocab,transform,batch_size,\n",
    "                        shuffle=False,num_workers=5)\n",
    "print(len(data_loader))\n",
    "encoder = EncoderCNN(embed_size).eval().to(device)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, len(vocab), num_layers).to(device)\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n",
    "decoder.load_state_dict(torch.load(decoder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(data_loader)\n",
    "output_list = []\n",
    "f=open('captions_test2014_cnnrnn_results.json','w')\n",
    "#image_id_dict = dict()\n",
    "index = 0\n",
    "for i,(images,image_id) in enumerate(data_loader):\n",
    "    index += 1\n",
    "    if(index%100==0):\n",
    "        print(index)\n",
    "    image_id = image_id.cpu().numpy().item()\n",
    "    #try:\n",
    "    #    if image_id_dict[image_id]==\"yes\":\n",
    "    #        continue\n",
    "    #except:\n",
    "    #    image_id_dict[image_id]=\"yes\"\n",
    "    #    pass\n",
    "    images = images.view([1,3,240,240]).to(device)\n",
    "    #print(images.size())\n",
    "    features = encoder(images)\n",
    "    sampled_ids = decoder.sample(features)\n",
    "    sampled_ids = sampled_ids[0].cpu().numpy()\n",
    "    sampled_caption = []\n",
    "    result_dict = dict()\n",
    "    for word_id in sampled_ids:\n",
    "        word = vocab.idx2word[word_id]\n",
    "        if word != '<end>' and word != '<start>':\n",
    "            sampled_caption.append(word)\n",
    "        if word == '<end>':\n",
    "            break\n",
    "    sentence = ' '.join(sampled_caption)\n",
    "    #print(sentence)\n",
    "    result_dict[\"image_id\"] = image_id\n",
    "    result_dict[\"caption\"] = sentence\n",
    "    output_list.append(result_dict)\n",
    "\n",
    "f.write(json.dumps(output_list))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
